import { z } from 'zod';
import { createTRPCRouter, protectedProcedure } from '../trpc';
import { TRPCError } from '@trpc/server';
import { compileWorkflow } from '@/lib/workflow-compiler/compiler';
import { storeCompiledCode } from '@/lib/workflow-compiler/storage';
import type { TemporalWorkflow } from '@/types/advanced-patterns';
import type { SupabaseClient } from '@supabase/supabase-js';

// Temporal integration via standalone worker service
const TEMPORAL_ENABLED = true;
const WORKER_SERVICE_URL = process.env.WORKER_SERVICE_URL || 'http://localhost:3011';

// Call worker service via HTTP instead of importing @temporalio/worker
async function startWorkerForProject(projectId: string) {
  const response = await fetch(`${WORKER_SERVICE_URL}/workers/start`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ projectId }),
  });
  
  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || 'Failed to start worker');
  }
  
  return response.json();
}

async function getTemporalClient() {
  // Dynamic import only for client (no worker dependencies)
  const { getTemporalClient: getClient } = await import('@/lib/temporal/connection');
  return getClient();
}

async function recordWorkflowStats(projectId: string, workflowId: string, durationMs: number, success: boolean) {
  // Dynamic import for statistics
  const { recordWorkflowExecution } = await import('@/lib/temporal/statistics');
  return recordWorkflowExecution(projectId, workflowId, durationMs, success);
}

/**
 * Monitor a Temporal workflow execution and update database when complete
 */
async function monitorExecution(
  handle: any, // WorkflowHandle type - using any to avoid import
  executionId: string,
  projectId: string,
  workflowId: string,
  startTime: Date,
  supabase: SupabaseClient
) {
  try {
    console.log(`ðŸ‘€ Monitoring workflow execution ${executionId}...`);
    
    // Wait for workflow to complete
    const result = await handle.result();
    const endTime = new Date();
    const durationMs = endTime.getTime() - startTime.getTime();
    
    console.log(`âœ… Workflow completed in ${durationMs}ms`);
    
    // Update execution record
    await supabase
      .from('workflow_executions')
      .update({
        status: 'completed',
        completed_at: endTime.toISOString(),
        output: result,
      })
      .eq('id', executionId);
    
    // Record statistics
    await recordWorkflowStats(projectId, workflowId, durationMs, true);
    
    console.log(`ðŸ“Š Execution recorded successfully`);
  } catch (error: any) {
    console.error(`âŒ Workflow execution failed:`, error);
    const endTime = new Date();
    const durationMs = endTime.getTime() - startTime.getTime();
    
    // Update execution with error
    await supabase
      .from('workflow_executions')
      .update({
        status: 'failed',
        completed_at: endTime.toISOString(),
        error_message: error.message || 'Unknown error',
      })
      .eq('id', executionId);
    
    // Record failed execution statistics
    await recordWorkflowStats(projectId, workflowId, durationMs, false);
  }
}

export const executionRouter = createTRPCRouter({
  /**
   * Build and execute a workflow
   * This creates a "build workflow" Temporal workflow that:
   * 1. Compiles the workflow definition
   * 2. Validates the generated code
   * 3. Creates/updates the worker configuration
   * 4. Starts the workflow execution
   */
  build: protectedProcedure
    .input(z.object({
      workflowId: z.string(),
      input: z.any().optional(),
    }))
    .mutation(async ({ ctx, input }) => {
      // Fetch workflow with all related data
      const { data: workflowData, error: workflowError } = await ctx.supabase
        .from('workflows')
        .select(`
          *,
          workflow_nodes(*),
          workflow_edges(*)
        `)
        .eq('id', input.workflowId)
        .eq('created_by', ctx.user.id)
        .single();

      if (workflowError || !workflowData) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Workflow not found or not authorized',
        });
      }

      // Fetch work queues, signals, queries
      const [
        { data: workQueues },
        { data: signals },
        { data: queries }
      ] = await Promise.all([
        ctx.supabase.from('workflow_work_queues').select('*').eq('workflow_id', input.workflowId),
        ctx.supabase.from('workflow_signals').select('*').eq('workflow_id', input.workflowId),
        ctx.supabase.from('workflow_queries').select('*').eq('workflow_id', input.workflowId),
      ]);

      // Convert to TemporalWorkflow format
      const workflow: TemporalWorkflow = {
        id: workflowData.id,
        name: workflowData.display_name || workflowData.kebab_name, // deprecated, kept for backward compatibility
        kebab_name: workflowData.kebab_name,
        display_name: workflowData.display_name,
        description: workflowData.description,
        stages: workflowData.workflow_nodes?.map((node: any) => ({
          id: node.node_id,
          type: node.node_type_id,
          position: { x: node.position_x, y: node.position_y },
          metadata: node.metadata,
        })) || [],
        transitions: workflowData.workflow_edges?.map((edge: any) => ({
          from: edge.source_node_id,
          to: edge.target_node_id,
          condition: edge.label,
        })) || [],
        workQueues: workQueues?.map(wq => ({
          id: wq.id,
          workflowId: wq.workflow_id,
          name: wq.queue_name,
          description: wq.description,
          signalName: wq.signal_name,
          queryName: wq.query_name,
          maxSize: wq.max_size,
          priority: wq.priority as 'fifo' | 'lifo' | 'priority',
          deduplicate: wq.deduplicate,
          workItemSchema: wq.work_item_schema,
          createdAt: new Date(wq.created_at),
          updatedAt: new Date(wq.updated_at),
        })) || [],
        signals: signals?.map(s => ({
          id: s.id,
          workflowId: s.workflow_id,
          name: s.signal_name,
          description: s.description,
          parametersSchema: s.parameters_schema,
          autoGenerated: s.auto_generated,
          createdAt: new Date(s.created_at),
        })) || [],
        queries: queries?.map(q => ({
          id: q.id,
          workflowId: q.workflow_id,
          name: q.query_name,
          description: q.description,
          returnTypeSchema: q.return_type_schema,
          autoGenerated: q.auto_generated,
          createdAt: new Date(q.created_at),
        })) || [],
      };

      // Create execution record
      const { data: execution, error: execError } = await ctx.supabase
        .from('workflow_executions')
        .insert({
          workflow_id: input.workflowId,
          status: 'building',
          started_at: new Date().toISOString(),
          input: input.input,
          created_by: ctx.user.id,
        })
        .select()
        .single();

      if (execError || !execution) {
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: 'Failed to create execution record',
        });
      }

      try {
        // Get user record for storage
        const userRecord = await ctx.getUserRecord();
        
        // Step 1: Compile workflow definition
        console.log(`ðŸ”¨ Compiling workflow ${workflowData.name}...`);
        const compiled = compileWorkflow(workflow, {
          includeComments: true,
          strictMode: true,
        });

        // Step 2: Store compiled code in database
        console.log(`ðŸ’¾ Storing compiled code...`);
        const codeId = await storeCompiledCode(
          input.workflowId,
          workflowData.version,
          compiled,
          userRecord.id
        );
        
        console.log(`âœ… Compiled code stored with ID: ${codeId}`);

        // Step 3: Get project for this workflow
        if (!workflowData.project_id) {
          throw new Error('Workflow has no associated project');
        }
        
        const { data: project } = await ctx.supabase
          .from('projects')
          .select('*')
          .eq('id', workflowData.project_id)
          .single();
        
        if (!project) {
          throw new Error('Project not found');
        }
        
        console.log(`ðŸ“‹ Project: ${project.name} (task queue: ${project.task_queue_name})`);

        if (!TEMPORAL_ENABLED) {
          // Temporal is disabled - just mark as completed with compiled code
          await ctx.supabase
            .from('workflow_executions')
            .update({
              status: 'completed',
              completed_at: new Date().toISOString(),
              output: { 
                message: 'Workflow compiled successfully. Temporal integration temporarily disabled.',
                compiledCodeId: codeId 
              },
            })
            .eq('id', execution.id);

          return {
            success: true,
            executionId: execution.id,
            message: `Workflow compiled successfully! Temporal integration is currently disabled. You can view the compiled code in the database.`,
          };
        }

        // Step 4: Ensure worker is running for this project (via worker service)
        console.log(`ðŸ”§ Ensuring worker is running for project...`);
        await startWorkerForProject(project.id);
        
        // Step 5: Get Temporal client
        console.log(`ðŸ“¦ Connecting to Temporal...`);
        const client = await getTemporalClient();
        
        // Step 6: Start workflow execution on Temporal
        console.log(`ðŸš€ Starting workflow execution on Temporal...`);
        
        const workflowId = `${workflowData.kebab_name || workflowData.name}-${Date.now()}`;
        const handle = await client.workflow.start(workflowData.kebab_name || workflowData.name, {
          taskQueue: project.task_queue_name,
          workflowId,
          args: [input.input || {}],
        });
        
        console.log(`âœ… Workflow started: ${workflowId}`);
        console.log(`   Run ID: ${handle.firstExecutionRunId}`);
        
        // Update execution with Temporal workflow ID
        await ctx.supabase
          .from('workflow_executions')
          .update({
            status: 'running',
            temporal_workflow_id: workflowId,
            temporal_run_id: handle.firstExecutionRunId,
          })
          .eq('id', execution.id);
        
        // Monitor execution in background (don't await)
        monitorExecution(
          handle,
          execution.id,
          project.id,
          workflowData.id,
          new Date(),
          ctx.supabase
        ).catch(err => console.error('Error monitoring execution:', err));
        
        return {
          success: true,
          executionId: execution.id,
          workflowId,
          runId: handle.firstExecutionRunId,
          message: 'Workflow execution started successfully!',
        };
      } catch (error: any) {
        console.error(`âŒ Build/execution failed:`, error);
        
        // Update execution with failure
        await ctx.supabase
          .from('workflow_executions')
          .update({
            status: 'failed',
            completed_at: new Date().toISOString(),
            error_message: error.message,
          })
          .eq('id', execution.id);

        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: `Build/execution failed: ${error.message}`,
          cause: error,
        });
      }
    }),

  /**
   * Get execution status
   */
  getStatus: protectedProcedure
    .input(z.object({
      executionId: z.string(),
    }))
    .query(async ({ ctx, input }) => {
      const { data, error } = await ctx.supabase
        .from('workflow_executions')
        .select('*')
        .eq('id', input.executionId)
        .eq('created_by', ctx.user.id)
        .single();

      if (error || !data) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Execution not found',
        });
      }

      return {
        id: data.id,
        status: data.status,
        startedAt: new Date(data.started_at),
        completedAt: data.completed_at ? new Date(data.completed_at) : null,
        result: data.output,  // Use 'output' column
        error: data.error_message,  // Use 'error_message' column
        input: data.input,
      };
    }),

  /**
   * List executions for a workflow
   */
  list: protectedProcedure
    .input(z.object({
      workflowId: z.string(),
      page: z.number().default(1),
      pageSize: z.number().default(10),
    }))
    .query(async ({ ctx, input }) => {
      const from = (input.page - 1) * input.pageSize;
      const to = from + input.pageSize - 1;

      const { data, error, count } = await ctx.supabase
        .from('workflow_executions')
        .select('*', { count: 'exact' })
        .eq('workflow_id', input.workflowId)
        .eq('created_by', ctx.user.id)
        .order('started_at', { ascending: false })
        .range(from, to);

      if (error) {
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error.message,
        });
      }

      return {
        executions: data?.map(e => ({
          id: e.id,
          status: e.status,
          startedAt: new Date(e.started_at),
          completedAt: e.completed_at ? new Date(e.completed_at) : null,
          result: e.output,  // Use 'output' column
          error: e.error_message,  // Use 'error_message' column
        })) || [],
        total: count || 0,
        page: input.page,
        pageSize: input.pageSize,
      };
    }),

  /**
   * Get detailed execution information including component-level details
   */
  getExecutionDetails: protectedProcedure
    .input(z.object({ executionId: z.string() }))
    .query(async ({ ctx, input }) => {
      // Check database (cache check)
      const { data: execution, error: execError } = await ctx.supabase
        .from('workflow_executions')
        .select('*')
        .eq('id', input.executionId)
        .eq('created_by', ctx.user.id)
        .single();

      if (execError || !execution) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Execution not found',
        });
      }

      // Check if needs syncing
      const { checkSyncStatus, requestSync } = await import('@/lib/temporal/sync-service');
      const { needsSync } = await checkSyncStatus(input.executionId);

      // If not synced or stale, trigger immediate sync
      if (needsSync && execution.temporal_workflow_id && execution.temporal_run_id) {
        await requestSync(input.executionId, true);
      }

      // Fetch component executions
      const { data: componentExecutions } = await ctx.supabase
        .from('component_executions')
        .select('*')
        .eq('workflow_execution_id', input.executionId)
        .order('started_at', { ascending: true });

      return {
        id: execution.id,
        workflowId: execution.workflow_id,
        status: execution.status,
        startedAt: new Date(execution.started_at),
        completedAt: execution.completed_at ? new Date(execution.completed_at) : null,
        durationMs: execution.duration_ms,
        input: execution.input,
        output: execution.output,
        error: execution.error_message,
        temporalWorkflowId: execution.temporal_workflow_id,
        temporalRunId: execution.temporal_run_id,
        historySyncStatus: execution.history_sync_status,
        historySyncedAt: execution.history_synced_at ? new Date(execution.history_synced_at) : null,
        componentExecutions: componentExecutions || [],
      };
    }),

  /**
   * Get execution history for a workflow with filtering
   */
  getExecutionHistory: protectedProcedure
    .input(z.object({
      workflowId: z.string(),
      page: z.number().default(1),
      pageSize: z.number().default(20),
      status: z.enum(['all', 'completed', 'failed', 'running']).optional(),
    }))
    .query(async ({ ctx, input }) => {
      const from = (input.page - 1) * input.pageSize;
      const to = from + input.pageSize - 1;

      let query = ctx.supabase
        .from('workflow_executions')
        .select('*', { count: 'exact' })
        .eq('workflow_id', input.workflowId)
        .eq('created_by', ctx.user.id);

      if (input.status && input.status !== 'all') {
        query = query.eq('status', input.status);
      }

      const { data, error, count } = await query
        .order('started_at', { ascending: false })
        .range(from, to);

      if (error) {
        throw new TRPCError({
          code: 'INTERNAL_SERVER_ERROR',
          message: error.message,
        });
      }

      return {
        executions: data?.map(e => ({
          id: e.id,
          status: e.status,
          startedAt: new Date(e.started_at),
          completedAt: e.completed_at ? new Date(e.completed_at) : null,
          durationMs: e.duration_ms,
          result: e.output,
          error: e.error_message,
          historySyncStatus: e.history_sync_status,
        })) || [],
        total: count || 0,
        page: input.page,
        pageSize: input.pageSize,
      };
    }),

  /**
   * Manually trigger sync from Temporal (cache-aside pattern)
   */
  syncExecutionFromTemporal: protectedProcedure
    .input(z.object({
      executionId: z.string(),
      immediate: z.boolean().default(false),
    }))
    .mutation(async ({ ctx, input }) => {
      // Verify execution belongs to user
      const { data: execution } = await ctx.supabase
        .from('workflow_executions')
        .select('id')
        .eq('id', input.executionId)
        .eq('created_by', ctx.user.id)
        .single();

      if (!execution) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Execution not found',
        });
      }

      // Request sync
      const { requestSync, waitForSync } = await import('@/lib/temporal/sync-service');
      const result = await requestSync(input.executionId, input.immediate);

      if (input.immediate && result.synced) {
        // Wait for sync to complete
        const waitResult = await waitForSync(input.executionId);
        return {
          success: waitResult.success,
          synced: waitResult.synced,
          componentExecutionsCount: result.componentExecutionsCount,
          error: waitResult.error,
        };
      }

      return result;
    }),

  /**
   * Get aggregated statistics for a workflow
   */
  getWorkflowStatistics: protectedProcedure
    .input(z.object({ workflowId: z.string() }))
    .query(async ({ ctx, input }) => {
      // Verify workflow belongs to user
      const { data: workflow } = await ctx.supabase
        .from('workflows')
        .select('id')
        .eq('id', input.workflowId)
        .eq('created_by', ctx.user.id)
        .single();

      if (!workflow) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Workflow not found',
        });
      }

      // Get statistics
      const { data: stats } = await ctx.supabase
        .from('workflow_statistics')
        .select('*')
        .eq('workflow_id', input.workflowId)
        .single();

      return stats || {
        total_runs: 0,
        successful_runs: 0,
        failed_runs: 0,
        avg_duration_ms: null,
        min_duration_ms: null,
        max_duration_ms: null,
        most_used_component_id: null,
        most_used_component_count: 0,
        total_errors: 0,
        last_error_at: null,
        last_run_at: null,
      };
    }),

  /**
   * Get aggregated statistics for a project
   */
  getProjectStatistics: protectedProcedure
    .input(z.object({ projectId: z.string() }))
    .query(async ({ ctx, input }) => {
      // Verify project belongs to user
      const { data: project } = await ctx.supabase
        .from('projects')
        .select('id')
        .eq('id', input.projectId)
        .eq('created_by', ctx.user.id)
        .single();

      if (!project) {
        throw new TRPCError({
          code: 'NOT_FOUND',
          message: 'Project not found',
        });
      }

      // Get statistics
      const { data: stats } = await ctx.supabase
        .from('project_statistics')
        .select('*')
        .eq('project_id', input.projectId)
        .single();

      return stats || {
        most_used_workflow_id: null,
        most_used_workflow_count: 0,
        most_used_component_id: null,
        most_used_component_count: 0,
        most_used_task_queue_id: null,
        most_used_task_queue_count: 0,
        total_executions: 0,
        longest_run_duration_ms: null,
        longest_run_workflow_id: null,
        total_failures: 0,
        last_failure_at: null,
        last_execution_at: null,
      };
    }),
});

